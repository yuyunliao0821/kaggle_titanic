{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599802023423",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        PassengerId    Survived      Pclass                     Name   Sex  \\\ncount    891.000000  891.000000  891.000000                      891   891   \nunique          NaN         NaN         NaN                      891     2   \ntop             NaN         NaN         NaN  Oreskovic, Miss. Marija  male   \nfreq            NaN         NaN         NaN                        1   577   \nmean     446.000000    0.383838    2.308642                      NaN   NaN   \nstd      257.353842    0.486592    0.836071                      NaN   NaN   \nmin        1.000000    0.000000    1.000000                      NaN   NaN   \n25%      223.500000    0.000000    2.000000                      NaN   NaN   \n50%      446.000000    0.000000    3.000000                      NaN   NaN   \n75%      668.500000    1.000000    3.000000                      NaN   NaN   \nmax      891.000000    1.000000    3.000000                      NaN   NaN   \n\n               Age       SibSp       Parch    Ticket        Fare        Cabin  \\\ncount   714.000000  891.000000  891.000000       891  891.000000          204   \nunique         NaN         NaN         NaN       681         NaN          147   \ntop            NaN         NaN         NaN  CA. 2343         NaN  C23 C25 C27   \nfreq           NaN         NaN         NaN         7         NaN            4   \nmean     29.699118    0.523008    0.381594       NaN   32.204208          NaN   \nstd      14.526497    1.102743    0.806057       NaN   49.693429          NaN   \nmin       0.420000    0.000000    0.000000       NaN    0.000000          NaN   \n25%      20.125000    0.000000    0.000000       NaN    7.910400          NaN   \n50%      28.000000    0.000000    0.000000       NaN   14.454200          NaN   \n75%      38.000000    1.000000    0.000000       NaN   31.000000          NaN   \nmax      80.000000    8.000000    6.000000       NaN  512.329200          NaN   \n\n       Embarked  \ncount       889  \nunique        3  \ntop           S  \nfreq        644  \nmean        NaN  \nstd         NaN  \nmin         NaN  \n25%         NaN  \n50%         NaN  \n75%         NaN  \nmax         NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891</td>\n      <td>891</td>\n      <td>714.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891</td>\n      <td>891.000000</td>\n      <td>204</td>\n      <td>889</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>891</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>681</td>\n      <td>NaN</td>\n      <td>147</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Oreskovic, Miss. Marija</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CA. 2343</td>\n      <td>NaN</td>\n      <td>C23 C25 C27</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>577</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>644</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>NaN</td>\n      <td>32.204208</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.526497</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>NaN</td>\n      <td>49.693429</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>7.910400</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>14.454200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>31.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>512.329200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_train.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              index  PassengerId    Survived       Pclass  \\\ncount   1309.000000  1309.000000  891.000000  1309.000000   \nunique          NaN          NaN         NaN          NaN   \ntop             NaN          NaN         NaN          NaN   \nfreq            NaN          NaN         NaN          NaN   \nmean     369.478992   655.000000    0.383838     2.294882   \nstd      248.767105   378.020061    0.486592     0.837836   \nmin        0.000000     1.000000    0.000000     1.000000   \n25%      163.000000   328.000000    0.000000     2.000000   \n50%      327.000000   655.000000    0.000000     3.000000   \n75%      563.000000   982.000000    1.000000     3.000000   \nmax      890.000000  1309.000000    1.000000     3.000000   \n\n                        Name   Sex          Age        SibSp        Parch  \\\ncount                   1309  1309  1046.000000  1309.000000  1309.000000   \nunique                  1307     2          NaN          NaN          NaN   \ntop     Connolly, Miss. Kate  male          NaN          NaN          NaN   \nfreq                       2   843          NaN          NaN          NaN   \nmean                     NaN   NaN    29.881138     0.498854     0.385027   \nstd                      NaN   NaN    14.413493     1.041658     0.865560   \nmin                      NaN   NaN     0.170000     0.000000     0.000000   \n25%                      NaN   NaN    21.000000     0.000000     0.000000   \n50%                      NaN   NaN    28.000000     0.000000     0.000000   \n75%                      NaN   NaN    39.000000     1.000000     0.000000   \nmax                      NaN   NaN    80.000000     8.000000     9.000000   \n\n          Ticket         Fare        Cabin Embarked  \ncount       1309  1308.000000          295     1307  \nunique       929          NaN          186        3  \ntop     CA. 2343          NaN  C23 C25 C27        S  \nfreq          11          NaN            6      914  \nmean         NaN    33.295479          NaN      NaN  \nstd          NaN    51.758668          NaN      NaN  \nmin          NaN     0.000000          NaN      NaN  \n25%          NaN     7.895800          NaN      NaN  \n50%          NaN    14.454200          NaN      NaN  \n75%          NaN    31.275000          NaN      NaN  \nmax          NaN   512.329200          NaN      NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>891.000000</td>\n      <td>1309.000000</td>\n      <td>1309</td>\n      <td>1309</td>\n      <td>1046.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309</td>\n      <td>1308.000000</td>\n      <td>295</td>\n      <td>1307</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1307</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>929</td>\n      <td>NaN</td>\n      <td>186</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Connolly, Miss. Kate</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CA. 2343</td>\n      <td>NaN</td>\n      <td>C23 C25 C27</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>843</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>914</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>369.478992</td>\n      <td>655.000000</td>\n      <td>0.383838</td>\n      <td>2.294882</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.881138</td>\n      <td>0.498854</td>\n      <td>0.385027</td>\n      <td>NaN</td>\n      <td>33.295479</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>248.767105</td>\n      <td>378.020061</td>\n      <td>0.486592</td>\n      <td>0.837836</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.413493</td>\n      <td>1.041658</td>\n      <td>0.865560</td>\n      <td>NaN</td>\n      <td>51.758668</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.170000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>163.000000</td>\n      <td>328.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>7.895800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>327.000000</td>\n      <td>655.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>14.454200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>563.000000</td>\n      <td>982.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>39.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>31.275000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>890.000000</td>\n      <td>1309.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>9.000000</td>\n      <td>NaN</td>\n      <td>512.329200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df_all = pd.concat([df_train,df_test], axis=0).reset_index()\n",
    "df_all.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      index  PassengerId  Survived  Pclass  \\\n0         0            1       0.0       3   \n1         1            2       1.0       1   \n2         2            3       1.0       3   \n3         3            4       1.0       1   \n4         4            5       0.0       3   \n...     ...          ...       ...     ...   \n1304    413         1305       NaN       3   \n1305    414         1306       NaN       1   \n1306    415         1307       NaN       3   \n1307    416         1308       NaN       3   \n1308    417         1309       NaN       3   \n\n                                                   Name  Sex   Age  SibSp  \\\n0                               Braund, Mr. Owen Harris    1  22.0      1   \n1     Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1   \n2                                Heikkinen, Miss. Laina    0  26.0      0   \n3          Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1   \n4                              Allen, Mr. William Henry    1  35.0      0   \n...                                                 ...  ...   ...    ...   \n1304                                 Spector, Mr. Woolf    1   NaN      0   \n1305                       Oliva y Ocana, Dona. Fermina    0  39.0      0   \n1306                       Saether, Mr. Simon Sivertsen    1  38.5      0   \n1307                                Ware, Mr. Frederick    1   NaN      0   \n1308                           Peter, Master. Michael J    1   NaN      1   \n\n      Parch              Ticket      Fare Cabin Embarked  \n0         0           A/5 21171    7.2500   NaN        S  \n1         0            PC 17599   71.2833   C85        C  \n2         0    STON/O2. 3101282    7.9250   NaN        S  \n3         0              113803   53.1000  C123        S  \n4         0              373450    8.0500   NaN        S  \n...     ...                 ...       ...   ...      ...  \n1304      0           A.5. 3236    8.0500   NaN        S  \n1305      0            PC 17758  108.9000  C105        C  \n1306      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n1307      0              359309    8.0500   NaN        S  \n1308      1                2668   22.3583   NaN        C  \n\n[1309 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>0</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>0</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1304</th>\n      <td>413</td>\n      <td>1305</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Spector, Mr. Woolf</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A.5. 3236</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1305</th>\n      <td>414</td>\n      <td>1306</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>Oliva y Ocana, Dona. Fermina</td>\n      <td>0</td>\n      <td>39.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>PC 17758</td>\n      <td>108.9000</td>\n      <td>C105</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>1306</th>\n      <td>415</td>\n      <td>1307</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Saether, Mr. Simon Sivertsen</td>\n      <td>1</td>\n      <td>38.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>SOTON/O.Q. 3101262</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1307</th>\n      <td>416</td>\n      <td>1308</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Ware, Mr. Frederick</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>359309</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1308</th>\n      <td>417</td>\n      <td>1309</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Peter, Master. Michael J</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2668</td>\n      <td>22.3583</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n<p>1309 rows × 13 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#encoding sex\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_all['Sex'])\n",
    "df_all['Sex']=le.transform(df_all['Sex'])\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting name into title\n",
    "df_all['title']=[ele.split(',')[1].split('.')[0].strip() for ele in df_all['Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce title categories\n",
    "new_title=[]\n",
    "for i in df_all['title']:\n",
    "    if i in ['Don','Rev','Dr','Mme','Ms','Major','Lady','Sir','Mlle','Col','Capt','the Countess','Jonkheer', 'Dona']:\n",
    "        new_title.append('Rare')\n",
    "    else:\n",
    "        new_title.append(i)\n",
    "\n",
    "df_all['new_title'] = new_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert title into dummy variables\n",
    "df_all = pd.get_dummies(df_all, columns=['new_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['title','Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Fare'] = df_all['Fare'].fillna(df_all['Fare'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Fare_band'] = pd.qcut(df_all['Fare'],5,labels=['0','1','2','3','4']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop('Fare', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "age_X_known = df_all.loc[df_all['Age'].notnull()].drop(['index', 'PassengerId','Survived','Ticket','Cabin','Age','Embarked'],axis=1)\n",
    "age_y_known = df_all.loc[df_all['Age'].notnull(),'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_X_unknown = df_all.loc[df_all['Age'].isnull()].drop(['index', 'PassengerId','Survived','Ticket','Cabin','Age','Embarked'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state=0, n_estimators=2000, n_jobs=-1)\n",
    "rfr.fit(age_X_known, age_y_known)\n",
    "predicted_age = rfr.predict(age_X_unknown)\n",
    "age_predicted_df = pd.DataFrame(predicted_age)\n",
    "df_all.loc[(df_all['Age'].isnull()), 'Age' ] = predicted_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Family_size'] = df_all['SibSp']+df_all['Parch']\n",
    "df_all = df_all.drop(['SibSp','Parch'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating 'is_alone' feature\n",
    "is_alone=[]\n",
    "for i in df_all['Family_size']:\n",
    "    if i==0:\n",
    "        is_alone.append(1)\n",
    "    else:\n",
    "        is_alone.append(0)\n",
    "is_alone_df = pd.DataFrame(is_alone)\n",
    "df_all['is_alone'] = is_alone_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['Family_size'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop ticket, cabin, passenger ID\n",
    "df_all = df_all.drop(['Ticket','Cabin','PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling Embarked missing value\n",
    "df_all['Embarked'] = df_all['Embarked'].fillna('S')\n",
    "#converting 'Embarked' column into one-hot form\n",
    "df_all = pd.get_dummies(df_all,columns=['Embarked'])\n",
    "df_all = df_all.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         Survived       Pclass          Sex          Age  new_title_Master  \\\ncount  891.000000  1309.000000  1309.000000  1309.000000       1309.000000   \nmean     0.383838     2.294882     0.644003    29.644055          0.046600   \nstd      0.486592     0.837836     0.478997    13.472213          0.210862   \nmin      0.000000     1.000000     0.000000     0.170000          0.000000   \n25%      0.000000     2.000000     0.000000    22.000000          0.000000   \n50%      0.000000     3.000000     1.000000    28.423509          0.000000   \n75%      1.000000     3.000000     1.000000    37.000000          0.000000   \nmax      1.000000     3.000000     1.000000    80.000000          1.000000   \n\n       new_title_Miss  new_title_Mr  new_title_Mrs  new_title_Rare  \\\ncount     1309.000000   1309.000000    1309.000000     1309.000000   \nmean         0.198625      0.578304       0.150497        0.025974   \nstd          0.399117      0.494019       0.357694        0.159119   \nmin          0.000000      0.000000       0.000000        0.000000   \n25%          0.000000      0.000000       0.000000        0.000000   \n50%          0.000000      1.000000       0.000000        0.000000   \n75%          0.000000      1.000000       0.000000        0.000000   \nmax          1.000000      1.000000       1.000000        1.000000   \n\n         Fare_band     is_alone   Embarked_C   Embarked_Q   Embarked_S  \ncount  1309.000000  1309.000000  1309.000000  1309.000000  1309.000000  \nmean      1.983957     0.603514     0.206264     0.093965     0.699771  \nstd       1.424626     0.489354     0.404777     0.291891     0.458533  \nmin       0.000000     0.000000     0.000000     0.000000     0.000000  \n25%       1.000000     0.000000     0.000000     0.000000     0.000000  \n50%       2.000000     1.000000     0.000000     0.000000     1.000000  \n75%       3.000000     1.000000     0.000000     0.000000     1.000000  \nmax       4.000000     1.000000     1.000000     1.000000     1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>new_title_Master</th>\n      <th>new_title_Miss</th>\n      <th>new_title_Mr</th>\n      <th>new_title_Mrs</th>\n      <th>new_title_Rare</th>\n      <th>Fare_band</th>\n      <th>is_alone</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.383838</td>\n      <td>2.294882</td>\n      <td>0.644003</td>\n      <td>29.644055</td>\n      <td>0.046600</td>\n      <td>0.198625</td>\n      <td>0.578304</td>\n      <td>0.150497</td>\n      <td>0.025974</td>\n      <td>1.983957</td>\n      <td>0.603514</td>\n      <td>0.206264</td>\n      <td>0.093965</td>\n      <td>0.699771</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.486592</td>\n      <td>0.837836</td>\n      <td>0.478997</td>\n      <td>13.472213</td>\n      <td>0.210862</td>\n      <td>0.399117</td>\n      <td>0.494019</td>\n      <td>0.357694</td>\n      <td>0.159119</td>\n      <td>1.424626</td>\n      <td>0.489354</td>\n      <td>0.404777</td>\n      <td>0.291891</td>\n      <td>0.458533</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.170000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>28.423509</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>37.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>80.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train = df_all.iloc[0:891,:]\n",
    "df_test = df_all.iloc[891:,:] #for submission use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('Survived',axis=1)\n",
    "y = df_train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "295"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = .33, random_state=0)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "596"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start building neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "class TitanicNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TitanicNet, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(13, 5),\n",
    "            nn.BatchNorm1d(5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5,2),\n",
    "            nn.Softmax() #See probability of each category\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic = TitanicNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "batch_no = len(X_train) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(Titanic.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n5\n10\n15\n20\n25\n30\n35\n40\n45\n"
    }
   ],
   "source": [
    "# training phase\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "Titanic.train()\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch%5 == 0:\n",
    "        print(epoch)\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "    for i in range(batch_no):\n",
    "        start = i * batch_size\n",
    "        end = start +batch_size\n",
    "        x_var = torch.FloatTensor(X_train[start:end].values)\n",
    "        y_var = torch.LongTensor(y_train[start:end].values)\n",
    "\n",
    "        #Forward+Backward+Optimize\n",
    "        optimizer.zero_grad()\n",
    "        ypred_var = Titanic(x_var)\n",
    "        loss = criterion(ypred_var, y_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[9.9932e-01, 1.6195e-03],\n        [9.9999e-01, 9.1262e-06],\n        [9.8984e-01, 1.3081e-02],\n        [1.6983e-05, 9.9999e-01],\n        [2.9366e-03, 9.9811e-01],\n        [9.9964e-01, 9.9530e-04],\n        [3.3489e-03, 9.9701e-01],\n        [2.5419e-02, 9.7261e-01],\n        [9.2874e-01, 1.5308e-01],\n        [9.3042e-04, 9.9943e-01],\n        [9.9999e-01, 1.9347e-05],\n        [7.7300e-02, 9.2714e-01],\n        [9.9999e-01, 3.0669e-05],\n        [2.6267e-01, 6.8240e-01],\n        [1.3710e-04, 9.9986e-01],\n        [4.0902e-01, 5.0937e-01],\n        [9.9998e-01, 2.3321e-05],\n        [9.9976e-01, 2.6113e-04],\n        [1.0000e+00, 5.0601e-06],\n        [1.5123e-02, 9.9005e-01],\n        [9.9963e-01, 4.3345e-04],\n        [3.1693e-03, 9.9683e-01],\n        [9.9999e-01, 3.0669e-05],\n        [9.9964e-01, 9.9530e-04],\n        [3.1972e-01, 6.2432e-01],\n        [2.2173e-05, 9.9999e-01],\n        [1.0000e+00, 6.2578e-06],\n        [3.8780e-01, 5.3918e-01],\n        [2.6590e-02, 9.7834e-01],\n        [7.4526e-01, 1.9694e-01],\n        [9.9949e-01, 1.2878e-03],\n        [1.9370e-01, 8.3578e-01],\n        [9.9999e-01, 1.0902e-05],\n        [9.9964e-01, 9.9530e-04],\n        [9.9999e-01, 9.7134e-06],\n        [5.0639e-03, 9.9758e-01],\n        [1.0000e+00, 2.2587e-06],\n        [9.9994e-01, 1.2338e-04],\n        [9.9992e-01, 1.5911e-04],\n        [9.9440e-01, 1.3960e-02],\n        [9.9676e-01, 1.3421e-02],\n        [9.9891e-01, 2.4116e-03],\n        [9.9999e-01, 1.1295e-05],\n        [9.9990e-01, 1.0912e-04],\n        [3.5465e-03, 9.9758e-01],\n        [9.9999e-01, 1.1419e-05],\n        [9.9999e-01, 1.1419e-05],\n        [4.9864e-04, 9.9947e-01],\n        [9.9997e-01, 7.3809e-05],\n        [9.9997e-01, 8.1988e-05],\n        [9.9964e-01, 9.9530e-04],\n        [9.1581e-01, 1.7325e-01],\n        [2.6916e-01, 6.7261e-01],\n        [9.9995e-01, 5.4157e-05],\n        [9.3893e-01, 1.6817e-01],\n        [9.9995e-01, 6.5787e-05],\n        [9.9990e-01, 3.7947e-04],\n        [7.2589e-01, 2.1907e-01],\n        [9.2673e-01, 8.0216e-02],\n        [9.9999e-01, 1.6620e-05],\n        [9.9844e-01, 3.1720e-03],\n        [4.2618e-01, 6.3768e-01],\n        [2.4654e-03, 9.9807e-01],\n        [2.1648e-02, 9.9198e-01],\n        [3.8269e-01, 6.7109e-01],\n        [9.9999e-01, 2.6190e-05],\n        [1.9524e-01, 8.7371e-01],\n        [9.8809e-01, 2.0177e-02],\n        [2.7353e-01, 6.6599e-01],\n        [4.4104e-03, 9.9530e-01],\n        [2.4349e-02, 9.7985e-01],\n        [9.9996e-01, 1.1019e-04],\n        [9.4472e-01, 1.2649e-01],\n        [9.9999e-01, 1.1419e-05],\n        [9.9999e-01, 1.7719e-05],\n        [3.9598e-02, 9.7005e-01],\n        [9.9860e-01, 1.6887e-03],\n        [1.0377e-02, 9.9563e-01],\n        [1.0000e+00, 4.2269e-06],\n        [9.9017e-01, 2.4615e-02],\n        [1.0000e+00, 7.1801e-06],\n        [8.8126e-01, 1.3381e-01],\n        [2.9031e-02, 9.7671e-01],\n        [9.9986e-01, 1.5104e-04],\n        [9.9998e-01, 7.2601e-05],\n        [3.2044e-03, 9.9679e-01],\n        [1.7757e-04, 9.9982e-01],\n        [7.6594e-01, 4.0116e-01],\n        [1.1937e-02, 9.9124e-01],\n        [8.7380e-01, 2.3268e-01],\n        [9.9957e-01, 1.0320e-03],\n        [9.9995e-01, 5.4157e-05],\n        [2.3452e-01, 7.6664e-01],\n        [3.1826e-05, 9.9998e-01],\n        [7.3027e-01, 2.1400e-01],\n        [9.9925e-01, 1.7793e-03],\n        [2.3415e-02, 9.8057e-01],\n        [9.9994e-01, 6.8933e-05],\n        [9.4155e-01, 1.4784e-01],\n        [7.6840e-01, 4.1372e-01],\n        [9.9991e-01, 8.8628e-05],\n        [9.9885e-01, 3.0049e-03],\n        [9.9993e-01, 7.5839e-05],\n        [9.9991e-01, 1.2149e-04],\n        [4.1642e-01, 6.4622e-01],\n        [5.6086e-01, 5.3042e-01],\n        [7.2597e-03, 9.9415e-01],\n        [6.9568e-01, 4.1125e-01],\n        [9.9994e-01, 6.6998e-05],\n        [2.8486e-01, 6.7804e-01],\n        [1.0000e+00, 1.7168e-06],\n        [2.8007e-02, 9.6880e-01],\n        [9.9999e-01, 1.7972e-05],\n        [3.1610e-01, 6.2960e-01],\n        [9.9989e-01, 2.6745e-04],\n        [4.0302e-02, 9.5453e-01],\n        [3.2100e-01, 7.1806e-01],\n        [4.1045e-06, 1.0000e+00],\n        [1.0000e+00, 3.8460e-06],\n        [1.4267e-01, 9.1150e-01],\n        [9.9999e-01, 2.0682e-05],\n        [9.9998e-01, 4.7979e-05],\n        [9.9996e-01, 4.3872e-05],\n        [6.6185e-01, 4.9647e-01],\n        [1.0000e+00, 5.6470e-06],\n        [9.8129e-01, 6.8970e-02],\n        [9.9925e-01, 1.7793e-03],\n        [9.9998e-01, 2.4342e-05],\n        [9.9996e-01, 8.9794e-05],\n        [9.9266e-01, 1.7365e-02],\n        [9.5424e-02, 8.9714e-01],\n        [9.9997e-01, 3.5539e-05],\n        [9.9998e-01, 1.9118e-05],\n        [8.1325e-01, 1.3723e-01],\n        [9.9991e-01, 3.4004e-04],\n        [9.9997e-01, 3.5539e-05],\n        [9.9999e-01, 1.1104e-05],\n        [6.5844e-01, 4.4756e-01],\n        [1.0000e+00, 7.7571e-06],\n        [9.9988e-01, 2.0331e-04],\n        [9.9993e-01, 1.3497e-04],\n        [4.6185e-03, 9.9610e-01],\n        [9.9999e-01, 1.1419e-05],\n        [7.8019e-02, 9.1137e-01],\n        [3.2894e-02, 9.6362e-01],\n        [3.1913e-01, 6.2757e-01],\n        [9.9994e-01, 1.2094e-04],\n        [1.1261e-01, 9.2783e-01],\n        [5.4726e-05, 9.9998e-01],\n        [9.9999e-01, 1.1419e-05],\n        [9.9995e-01, 1.3754e-04],\n        [3.4623e-01, 6.3649e-01],\n        [5.4919e-01, 4.5226e-01],\n        [9.9999e-01, 9.3048e-06],\n        [1.3548e-03, 9.9840e-01],\n        [9.9992e-01, 1.4629e-04],\n        [1.2346e-02, 9.9385e-01],\n        [1.0000e+00, 1.4467e-05],\n        [1.0887e-01, 8.8657e-01],\n        [5.1285e-02, 9.3246e-01],\n        [9.9999e-01, 1.1419e-05],\n        [9.9753e-01, 4.3441e-03],\n        [7.8549e-05, 9.9997e-01],\n        [5.1599e-01, 5.6701e-01],\n        [9.9113e-01, 1.5200e-02],\n        [9.9998e-01, 1.9118e-05],\n        [1.0000e+00, 1.4562e-06],\n        [9.9997e-01, 3.8077e-05],\n        [9.9998e-01, 1.8992e-05],\n        [9.9992e-01, 8.5278e-05],\n        [1.0000e+00, 2.1031e-06],\n        [1.8508e-05, 9.9999e-01],\n        [9.9999e-01, 9.1262e-06],\n        [9.9999e-01, 1.1295e-05],\n        [1.3473e-02, 9.8217e-01],\n        [9.9999e-01, 1.1419e-05],\n        [5.3769e-04, 9.9944e-01],\n        [9.9997e-01, 3.0264e-05],\n        [9.9995e-01, 5.4157e-05],\n        [3.6203e-03, 9.9775e-01],\n        [9.9995e-01, 9.8842e-05],\n        [9.9765e-01, 6.0395e-03],\n        [9.9753e-01, 4.3441e-03],\n        [9.9996e-01, 4.7908e-05],\n        [9.9966e-01, 9.3787e-04],\n        [9.9997e-01, 2.8789e-05],\n        [8.4448e-02, 9.1650e-01],\n        [9.9996e-01, 8.9794e-05],\n        [9.9999e-01, 1.5195e-05],\n        [2.2594e-01, 7.3764e-01],\n        [8.1156e-01, 1.3901e-01],\n        [9.9982e-01, 3.8698e-04],\n        [1.3628e-02, 9.8202e-01],\n        [1.0887e-01, 8.8657e-01],\n        [9.9999e-01, 3.0669e-05],\n        [9.9794e-01, 9.3129e-03],\n        [9.9999e-01, 1.1419e-05],\n        [7.7763e-01, 1.5537e-01],\n        [9.9922e-01, 1.7613e-03],\n        [1.0000e+00, 1.6251e-06],\n        [9.9994e-01, 6.7779e-05],\n        [5.5380e-02, 9.2876e-01],\n        [1.0000e+00, 9.3267e-06],\n        [5.5158e-02, 9.2896e-01],\n        [9.9995e-01, 5.4157e-05],\n        [9.9743e-01, 6.4998e-03],\n        [4.7085e-01, 6.0288e-01],\n        [1.0000e+00, 6.2578e-06],\n        [6.8083e-02, 9.1984e-01],\n        [1.0000e+00, 2.2217e-06],\n        [9.9998e-01, 2.4054e-05],\n        [4.2608e-02, 9.8589e-01],\n        [8.6034e-01, 1.4800e-01],\n        [5.3665e-02, 9.3030e-01],\n        [9.9995e-01, 1.0259e-04],\n        [9.9995e-01, 5.4157e-05],\n        [9.9795e-01, 5.4091e-03],\n        [5.2150e-01, 4.9242e-01],\n        [7.6642e-01, 3.4199e-01],\n        [1.4466e-04, 9.9985e-01],\n        [9.9993e-01, 7.5839e-05],\n        [5.0739e-04, 9.9947e-01],\n        [7.9411e-01, 1.5102e-01],\n        [9.9999e-01, 1.0902e-05],\n        [8.1824e-01, 1.3201e-01],\n        [1.0000e+00, 3.8953e-06],\n        [9.9997e-01, 3.8077e-05],\n        [3.2857e-02, 9.7975e-01],\n        [9.9998e-01, 1.9118e-05],\n        [9.9995e-01, 6.1303e-05],\n        [1.0000e+00, 5.6470e-06],\n        [1.7964e-01, 7.9734e-01],\n        [3.5187e-01, 6.0158e-01],\n        [2.5854e-01, 7.0242e-01],\n        [9.9984e-01, 5.2734e-04],\n        [1.0000e+00, 6.1664e-06],\n        [1.4614e-04, 9.9985e-01],\n        [2.6482e-01, 6.7915e-01],\n        [1.0022e-01, 9.3492e-01],\n        [9.9999e-01, 9.1262e-06],\n        [9.9925e-01, 1.7793e-03],\n        [1.6266e-02, 9.9154e-01],\n        [1.0000e+00, 6.2578e-06],\n        [9.9994e-01, 1.3276e-04],\n        [2.9237e-02, 9.6694e-01],\n        [6.9839e-02, 9.5343e-01],\n        [8.4448e-02, 9.1650e-01],\n        [9.9999e-01, 1.1419e-05],\n        [9.9999e-01, 1.1419e-05],\n        [3.8269e-01, 6.7109e-01],\n        [9.9997e-01, 2.8789e-05],\n        [9.9992e-01, 9.7041e-05],\n        [9.9130e-01, 2.9758e-02],\n        [9.9996e-01, 8.9794e-05],\n        [6.5023e-01, 3.0038e-01],\n        [2.1564e-01, 7.9872e-01],\n        [1.0887e-01, 8.8657e-01],\n        [1.0000e+00, 2.9231e-06],\n        [7.0244e-01, 3.0329e-01],\n        [1.0000e+00, 3.1670e-06],\n        [9.9999e-01, 1.1419e-05],\n        [9.9949e-01, 8.5502e-04],\n        [9.9954e-01, 1.1965e-03],\n        [9.9957e-01, 1.0442e-03],\n        [9.9998e-01, 6.3031e-05],\n        [9.9972e-01, 5.6500e-04],\n        [3.9837e-01, 5.2430e-01],\n        [9.3893e-01, 1.6817e-01],\n        [9.9978e-01, 6.9371e-04],\n        [4.9999e-05, 9.9998e-01],\n        [6.6209e-01, 3.2863e-01],\n        [9.9998e-01, 7.0722e-05],\n        [2.7866e-03, 9.9819e-01],\n        [4.9890e-01, 5.5094e-01],\n        [9.2252e-01, 1.6291e-01],\n        [9.9996e-01, 4.3872e-05],\n        [1.0000e+00, 8.2596e-06],\n        [9.9998e-01, 2.4054e-05],\n        [1.0887e-01, 8.8657e-01],\n        [3.8519e-01, 5.4288e-01],\n        [9.9998e-01, 1.9118e-05],\n        [2.8486e-01, 6.7804e-01],\n        [9.9964e-01, 9.9530e-04],\n        [2.3462e-03, 9.9865e-01],\n        [1.0000e+00, 4.1219e-07],\n        [9.9998e-01, 2.3321e-05],\n        [9.9449e-01, 9.6561e-03],\n        [7.3580e-01, 2.0766e-01],\n        [9.9999e-01, 3.6168e-05],\n        [9.9922e-01, 1.9977e-03],\n        [9.9995e-01, 1.0448e-04],\n        [9.9999e-01, 1.9306e-05],\n        [4.8298e-03, 9.9714e-01],\n        [5.8024e-02, 9.5871e-01],\n        [4.2049e-02, 9.5186e-01]])\ntensor([0.9993, 1.0000, 0.9898, 1.0000, 0.9981, 0.9996, 0.9970, 0.9726, 0.9287,\n        0.9994, 1.0000, 0.9271, 1.0000, 0.6824, 0.9999, 0.5094, 1.0000, 0.9998,\n        1.0000, 0.9901, 0.9996, 0.9968, 1.0000, 0.9996, 0.6243, 1.0000, 1.0000,\n        0.5392, 0.9783, 0.7453, 0.9995, 0.8358, 1.0000, 0.9996, 1.0000, 0.9976,\n        1.0000, 0.9999, 0.9999, 0.9944, 0.9968, 0.9989, 1.0000, 0.9999, 0.9976,\n        1.0000, 1.0000, 0.9995, 1.0000, 1.0000, 0.9996, 0.9158, 0.6726, 0.9999,\n        0.9389, 0.9999, 0.9999, 0.7259, 0.9267, 1.0000, 0.9984, 0.6377, 0.9981,\n        0.9920, 0.6711, 1.0000, 0.8737, 0.9881, 0.6660, 0.9953, 0.9798, 1.0000,\n        0.9447, 1.0000, 1.0000, 0.9701, 0.9986, 0.9956, 1.0000, 0.9902, 1.0000,\n        0.8813, 0.9767, 0.9999, 1.0000, 0.9968, 0.9998, 0.7659, 0.9912, 0.8738,\n        0.9996, 0.9999, 0.7666, 1.0000, 0.7303, 0.9992, 0.9806, 0.9999, 0.9416,\n        0.7684, 0.9999, 0.9989, 0.9999, 0.9999, 0.6462, 0.5609, 0.9942, 0.6957,\n        0.9999, 0.6780, 1.0000, 0.9688, 1.0000, 0.6296, 0.9999, 0.9545, 0.7181,\n        1.0000, 1.0000, 0.9115, 1.0000, 1.0000, 1.0000, 0.6618, 1.0000, 0.9813,\n        0.9992, 1.0000, 1.0000, 0.9927, 0.8971, 1.0000, 1.0000, 0.8132, 0.9999,\n        1.0000, 1.0000, 0.6584, 1.0000, 0.9999, 0.9999, 0.9961, 1.0000, 0.9114,\n        0.9636, 0.6276, 0.9999, 0.9278, 1.0000, 1.0000, 1.0000, 0.6365, 0.5492,\n        1.0000, 0.9984, 0.9999, 0.9939, 1.0000, 0.8866, 0.9325, 1.0000, 0.9975,\n        1.0000, 0.5670, 0.9911, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000,\n        1.0000, 1.0000, 1.0000, 0.9822, 1.0000, 0.9994, 1.0000, 0.9999, 0.9978,\n        1.0000, 0.9976, 0.9975, 1.0000, 0.9997, 1.0000, 0.9165, 1.0000, 1.0000,\n        0.7376, 0.8116, 0.9998, 0.9820, 0.8866, 1.0000, 0.9979, 1.0000, 0.7776,\n        0.9992, 1.0000, 0.9999, 0.9288, 1.0000, 0.9290, 0.9999, 0.9974, 0.6029,\n        1.0000, 0.9198, 1.0000, 1.0000, 0.9859, 0.8603, 0.9303, 1.0000, 0.9999,\n        0.9979, 0.5215, 0.7664, 0.9999, 0.9999, 0.9995, 0.7941, 1.0000, 0.8182,\n        1.0000, 1.0000, 0.9797, 1.0000, 0.9999, 1.0000, 0.7973, 0.6016, 0.7024,\n        0.9998, 1.0000, 0.9998, 0.6792, 0.9349, 1.0000, 0.9992, 0.9915, 1.0000,\n        0.9999, 0.9669, 0.9534, 0.9165, 1.0000, 1.0000, 0.6711, 1.0000, 0.9999,\n        0.9913, 1.0000, 0.6502, 0.7987, 0.8866, 1.0000, 0.7024, 1.0000, 1.0000,\n        0.9995, 0.9995, 0.9996, 1.0000, 0.9997, 0.5243, 0.9389, 0.9998, 1.0000,\n        0.6621, 1.0000, 0.9982, 0.5509, 0.9225, 1.0000, 1.0000, 1.0000, 0.8866,\n        0.5429, 1.0000, 0.6780, 0.9996, 0.9987, 1.0000, 1.0000, 0.9945, 0.7358,\n        1.0000, 0.9992, 1.0000, 1.0000, 0.9971, 0.9587, 0.9519])\n"
    }
   ],
   "source": [
    "#Evaluating using the validation set\n",
    "val = torch.tensor(X_test.values).float()\n",
    "Titanic.eval() #Need to switch to evaluation mode to turn off Batch Normalization\n",
    "with torch.no_grad():\n",
    "    result = Titanic(val)\n",
    "\n",
    "values, labels = torch.max(result, 1) \n",
    "#torch.max(a,1)會回傳一個tuple(value, index)，記載a的每一列中的最大值(value)和最大值出現的位置(index)\n",
    "\n",
    "print(result)\n",
    "print(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(labels.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n         0.0       0.84      0.88      0.86       184\n         1.0       0.78      0.71      0.75       111\n\n    accuracy                           0.82       295\n   macro avg       0.81      0.80      0.80       295\nweighted avg       0.82      0.82      0.82       295\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying to test data\n",
    "testing = torch.tensor(df_test.drop('Survived', axis=1).values, requires_grad=True).float()\n",
    "Titanic.eval()\n",
    "with torch.no_grad():\n",
    "        result = Titanic(testing)\n",
    "\n",
    "values, labels = torch.max(result, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = labels.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerId = pd.read_csv('test.csv')['PassengerId']\n",
    "submission = pd.DataFrame({'PassengerId':passengerId, 'Survived':res})\n",
    "submission['Survived'] = submission['Survived'].astype(int)\n",
    "submission.to_csv('submission_NN.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.return_types.max(\nvalues=tensor([2., 1., 0.]),\nindices=tensor([1, 1, 1]))"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "a= torch.tensor([[1,2],[0,1],[-1,0]]).float()\n",
    "torch.max(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}